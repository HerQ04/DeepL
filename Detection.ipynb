{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/HerQTheToxic/DeepL/blob/main/Detection.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "FcQ8O4-SnSyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Image path\n",
        "imagePath=\"/content/Test.png\""
      ],
      "metadata": {
        "id": "J2GYcXDUIGQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxldPEZMFjpT"
      },
      "outputs": [],
      "source": [
        "#YOLOv5 dependencies\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import cv2\n",
        "import torch\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "Xm7r30k0E42Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading trained model weights (stored in my public drive)\n",
        "!gdown https://drive.google.com/uc?id=1a59RBjKrMXo2szDmEELmzsnAlg7aW5un -O /content/Number.pt\n",
        "!gdown https://drive.google.com/uc?id=1BpJhTWsGL6ZvtPrDqbGiYV4DJXMW0QoF -O /content/Gem2.pt\n",
        "!gdown https://drive.google.com/uc?id=1jmatSFxw_TgjMyowckzvDAKBx50HPNOz -O /content/GemCls.pt\n",
        "!gdown https://drive.google.com/uc?id=1XZN4jWr1T36iaoXDllla3bJuTEvj8SwK -O /content/Test.png"
      ],
      "metadata": {
        "id": "jitGCvppVDxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EWym17P7nRcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLOv5 framework path\n",
        "yolov5Path = \"/content/yolov5\"\n",
        "\n",
        "#modell weight paths\n",
        "NumberModelPath=\"/content/Number.pt\"\n",
        "GemModelPath=\"/content/Gem2.pt\"\n",
        "GemModelClassPath=\"/content/GemCls.pt\""
      ],
      "metadata": {
        "id": "fYPfLn5LCuf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Detecting with the modell\n",
        "def detectx(frame, model):\n",
        "    results = model([frame])\n",
        "    labels, coordinates = results.pred[0][:, -1], results.pred[0][:, :-1]\n",
        "    return labels, coordinates"
      ],
      "metadata": {
        "id": "rf3Ob1ArH5Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading model with the trained weight\n",
        "def loadModel(path):\n",
        "    model = torch.hub.load(yolov5Path, 'custom', source='local', path=path, force_reload=True, skip_validation=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Zs6w4Ss95WPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting image into useable frame for detection\n",
        "def getFrame(image_path):\n",
        "    frame = cv2.imread(image_path)\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    return frame"
      ],
      "metadata": {
        "id": "jnoNspMk_uFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the numbers in the picture. Sorting in order by X coordinate and converting to final number\n",
        "def getDetectedNumber(frame, model):\n",
        "        #Getting the numbers\n",
        "    detectedNumbers = []\n",
        "\n",
        "    labelsNum, coordinatesNum = detectx(frame, model)\n",
        "    class_names_Num = model.names\n",
        "\n",
        "    for i in range(len(labelsNum)):\n",
        "            label = labelsNum[i]\n",
        "            coordinate = coordinatesNum[i]\n",
        "            if coordinate[4] >= threshold:\n",
        "                class_label = class_names_Num[int(label)]\n",
        "                x1, y1, x2, y2 = coordinate[:4]\n",
        "                detectedNumbers.append((class_label, x1))\n",
        "    if len(detectedNumbers) < 1:\n",
        "        return 0\n",
        "    else:\n",
        "        detectedNumbers = sorted(detectedNumbers, key=lambda x: x[1])\n",
        "\n",
        "        result_number = int(''.join(map(str, [obj[0] for obj in detectedNumbers])))\n",
        "        result_number = int(result_number)\n",
        "\n",
        "        return result_number"
      ],
      "metadata": {
        "id": "lKBRITx6_S8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find a gemstone in the picture. Return: gemstone class, confidence and the stone itself cut out of the image to be given to a classifier later\n",
        "def getDetectedGemFrameAndPred(frame, model):\n",
        "    labelsGem, coordinatesGem = detectx(frame, model)\n",
        "    class_names_Gem = model.names\n",
        "    for i in range(len(labelsGem)):\n",
        "        label = labelsGem[i]\n",
        "        coordinate = coordinatesGem[i]\n",
        "        if coordinate[4] >= threshold:\n",
        "            class_label = class_names_Gem[int(label)]\n",
        "            x1, y1, x2, y2 = map(int,coordinate[:4])\n",
        "            detected_object = frameGem[y1:y2, x1:x2]\n",
        "\n",
        "        return detected_object, class_label ,coordinate[4]\n",
        "    return None, None, None"
      ],
      "metadata": {
        "id": "gv8RXe0-DXDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization for image classification\n",
        "IMAGENET_MEAN = 0.485, 0.456, 0.406\n",
        "IMAGENET_STD = 0.229, 0.224, 0.225\n",
        "\n",
        "#Image transform for model\n",
        "def classify_transforms(size=224):\n",
        "    return T.Compose([T.ToTensor(), T.Resize(size), T.CenterCrop(size), T.Normalize(IMAGENET_MEAN, IMAGENET_STD)])"
      ],
      "metadata": {
        "id": "NgV1Y_HSBy0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms as T\n",
        "\n",
        "#Classification of the given image pieces\n",
        "def GemClass(model, decObj):\n",
        "    transformations = classify_transforms()\n",
        "    converted_tensor = transformations(Image.fromarray(cv2.cvtColor(decObj, cv2.COLOR_BGR2RGB)))\n",
        "    converted_tensor = converted_tensor.unsqueeze(0)\n",
        "\n",
        "    results = model(converted_tensor)\n",
        "    pred = F.softmax(results, dim=1)\n",
        "\n",
        "    max_confidence, max_class_idx = torch.max(pred, dim=1)\n",
        "    predGem=model.names[max_class_idx.item()]\n",
        "    conf=max_confidence.item()\n",
        "\n",
        "    return predGem, conf"
      ],
      "metadata": {
        "id": "FdrNotEfLJyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "#Loading models\n",
        "try:\n",
        "    modelNumber=loadModel(NumberModelPath)\n",
        "    modelGem = loadModel(GemModelPath)\n",
        "    modelGemClass = loadModel(GemModelClassPath)\n",
        "except:\n",
        "    print('Error with loading models')\n",
        "\n",
        "#Setting treshold\n",
        "global threshold\n",
        "threshold=0.1\n",
        "\n",
        "#Reading images\n",
        "try:\n",
        "\n",
        "    frameNumber =getFrame(imagePath)\n",
        "    frameGem = getFrame(imagePath)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'Error reading the image: {str(e)}')\n",
        "\n",
        "\n",
        "#Detected number\n",
        "result_number=getDetectedNumber(frameNumber,modelNumber)\n",
        "#Detected gem\n",
        "detected_Gem, predObj, confObj=getDetectedGemFrameAndPred(frameGem, modelGem)\n",
        "\n",
        "\n",
        "if detected_Gem is None:\n",
        "    clear_output()\n",
        "    print(f'there is no detected Gem on the picture')\n",
        "else:\n",
        "    #Using classification after object detection, to make better prediction\n",
        "    predClass,confCls =GemClass(modelGemClass, detected_Gem)\n",
        "    clear_output()\n",
        "    print(f'Gemstone\\'s weight: {result_number}, pred: {predObj}/{predClass}  confidence: {confObj}/{confCls}')\n",
        "\n"
      ],
      "metadata": {
        "id": "8tYWgZHqIiRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}